{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#to ensure clean outputs ignore the warning messages \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sysBP</th>\n",
       "      <th>glucose</th>\n",
       "      <th>totChol</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>age_group</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>gender</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sysBP  glucose  totChol  cigsPerDay  diaBP  prevalentHyp  age_group  \\\n",
       "0  106.0     77.0    195.0         0.0   70.0             0          2   \n",
       "1  121.0     76.0    250.0         0.0   81.0             0          3   \n",
       "2  127.5     70.0    245.0        20.0   80.0             0          3   \n",
       "3  150.0    103.0    225.0        30.0   95.0             1          5   \n",
       "4  130.0     85.0    285.0        23.0   84.0             0          3   \n",
       "\n",
       "   diabetes  BPMeds  gender  TenYearCHD  \n",
       "0         0     0.0       1           0  \n",
       "1         0     0.0       0           0  \n",
       "2         0     0.0       1           0  \n",
       "3         0     0.0       0           1  \n",
       "4         0     0.0       0           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the datafile\n",
    "df = pd.read_csv('03_FE_CHD_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sysBP</th>\n",
       "      <td>3658.0</td>\n",
       "      <td>132.370558</td>\n",
       "      <td>22.086866</td>\n",
       "      <td>83.5</td>\n",
       "      <td>117.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>143.875</td>\n",
       "      <td>295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>3658.0</td>\n",
       "      <td>81.852925</td>\n",
       "      <td>23.904164</td>\n",
       "      <td>40.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.000</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totChol</th>\n",
       "      <td>3658.0</td>\n",
       "      <td>236.847731</td>\n",
       "      <td>44.097681</td>\n",
       "      <td>113.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>263.000</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cigsPerDay</th>\n",
       "      <td>3658.0</td>\n",
       "      <td>9.025424</td>\n",
       "      <td>11.921590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diaBP</th>\n",
       "      <td>3658.0</td>\n",
       "      <td>82.917031</td>\n",
       "      <td>11.974258</td>\n",
       "      <td>48.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>90.000</td>\n",
       "      <td>142.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevalentHyp</th>\n",
       "      <td>3658.0</td>\n",
       "      <td>0.311646</td>\n",
       "      <td>0.463229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_group</th>\n",
       "      <td>3658.0</td>\n",
       "      <td>3.400765</td>\n",
       "      <td>0.931108</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>3658.0</td>\n",
       "      <td>0.027064</td>\n",
       "      <td>0.162292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPMeds</th>\n",
       "      <td>3658.0</td>\n",
       "      <td>0.030344</td>\n",
       "      <td>0.171557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>3658.0</td>\n",
       "      <td>0.443685</td>\n",
       "      <td>0.496886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TenYearCHD</th>\n",
       "      <td>3658.0</td>\n",
       "      <td>0.152269</td>\n",
       "      <td>0.359331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count        mean        std    min    25%    50%      75%  \\\n",
       "sysBP         3658.0  132.370558  22.086866   83.5  117.0  128.0  143.875   \n",
       "glucose       3658.0   81.852925  23.904164   40.0   71.0   78.0   87.000   \n",
       "totChol       3658.0  236.847731  44.097681  113.0  206.0  234.0  263.000   \n",
       "cigsPerDay    3658.0    9.025424  11.921590    0.0    0.0    0.0   20.000   \n",
       "diaBP         3658.0   82.917031  11.974258   48.0   75.0   82.0   90.000   \n",
       "prevalentHyp  3658.0    0.311646   0.463229    0.0    0.0    0.0    1.000   \n",
       "age_group     3658.0    3.400765   0.931108    2.0    3.0    3.0    4.000   \n",
       "diabetes      3658.0    0.027064   0.162292    0.0    0.0    0.0    0.000   \n",
       "BPMeds        3658.0    0.030344   0.171557    0.0    0.0    0.0    0.000   \n",
       "gender        3658.0    0.443685   0.496886    0.0    0.0    0.0    1.000   \n",
       "TenYearCHD    3658.0    0.152269   0.359331    0.0    0.0    0.0    0.000   \n",
       "\n",
       "                max  \n",
       "sysBP         295.0  \n",
       "glucose       394.0  \n",
       "totChol       600.0  \n",
       "cigsPerDay     70.0  \n",
       "diaBP         142.5  \n",
       "prevalentHyp    1.0  \n",
       "age_group       5.0  \n",
       "diabetes        1.0  \n",
       "BPMeds          1.0  \n",
       "gender          1.0  \n",
       "TenYearCHD      1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['TenYearCHD'])\n",
    "y = df.TenYearCHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run KNN model\n",
    "param_grid = {'n_neighbors':np.arange(1,50)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv= GridSearchCV(knn,param_grid,cv=5, n_jobs =4, scoring = 'roc_auc')\n",
    "knn_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters: \" + str(knn_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute roc_auc for the best hyperparameter\n",
    "knn = KNeighborsClassifier(n_neighbors=49)\n",
    "knn.fit(X_train, y_train)\n",
    "cv_scores_test= cross_val_score(knn,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_knn_test= cv_scores_test.mean()\n",
    "print(cv_scores_knn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty': ['l1', 'l2'], 'C': [0.0001, 0.001,0.01,0.1,1,5,10,100], 'solver': ['liblinear']}\n",
    "logreg = LogisticRegression()\n",
    "logreg_cv= GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, n_jobs =4, scoring = 'roc_auc')\n",
    "logreg_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters: \" + str(logreg_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute roc_auc for train and test set\n",
    "logreg = LogisticRegression(penalty = 'l2', C=0.1, solver='liblinear')\n",
    "logreg.fit(X_train,y_train)\n",
    "cv_scores_test= cross_val_score(logreg,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_logreg_test= cv_scores_test.mean()\n",
    "print(cv_scores_logreg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [5,6,7,8,9,10,15],\n",
    "    'n_estimators': [10, 50, 100, 200, 300]\n",
    "}\n",
    "rf = RandomForestClassifier()\n",
    "rf_cv= GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs =4, scoring = 'roc_auc')\n",
    "rf_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters: \" + str(rf_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute roc_auc for train and test set\n",
    "rf = RandomForestClassifier(criterion = 'gini', max_depth=6, n_estimators=50)\n",
    "rf.fit(X_train,y_train)\n",
    "cv_scores_test= cross_val_score(rf,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_rf_test= cv_scores_test.mean()\n",
    "print(cv_scores_rf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001], 'n_estimators':[100,200,500,1000],\n",
    "              'max_depth': [5, 10, 15, 20], 'min_samples_leaf': [100,150],'max_features': [0.3, 0.1]}\n",
    "GB = GradientBoostingClassifier(max_depth=4, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10)\n",
    "GB_cv= GridSearchCV(estimator=GB, param_grid=param_grid, cv=5, n_jobs =4, scoring = 'roc_auc')\n",
    "GB_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters: \" + str(GB_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute roc_auc for train and test set\n",
    "GB = GradientBoostingClassifier(learning_rate=0.01, max_depth= 10, max_features= 0.1, min_samples_leaf= 150, n_estimators= 1000)\n",
    "GB.fit(X_train,y_train)\n",
    "cv_scores_test= cross_val_score(GB,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_gbc_test= cv_scores_test.mean()\n",
    "print(cv_scores_gbc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}\n",
    " ]\n",
    "svm = SVC()\n",
    "svm_cv= GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, n_jobs =4, scoring = 'roc_auc')\n",
    "svm_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters: \" + str(svm_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compute roc_auc for train and test set\n",
    "svm = SVC(C=100, kernel = 'linear', probability=True)\n",
    "svm.fit(X_train,y_train)\n",
    "cv_scores_test= cross_val_score(svm,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_svm_test= cv_scores_test.mean()\n",
    "print(cv_scores_svm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "GB = GaussianNB()\n",
    "GB.fit(X_train,y_train)\n",
    "cv_scores_test= cross_val_score(GB,X_test,y_test,cv=5,scoring='roc_auc')\n",
    "cv_scores_nb_test= cv_scores_test.mean()\n",
    "print(cv_scores_nb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myLabels = ['KNN','Logistic Regression','Random Forest','Gradient Boost','SVM', 'Naive Bayes']\n",
    "score_test= [cv_scores_knn_test, cv_scores_logreg_test, cv_scores_rf_test, cv_scores_gbc_test, cv_scores_svm_test, cv_scores_nb_test]\n",
    "\n",
    "score_tab = pd.DataFrame(list(zip(myLabels, score_test)), \n",
    "               columns =['Algorithm', 'ROC-AUC score']) \n",
    "score_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I evaluated different algorithm, I found that __logistic regression__ performed best based on roc_auc score with roc_auc score of 0.76."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       923\n",
      "           1       0.79      0.06      0.12       175\n",
      "\n",
      "    accuracy                           0.85      1098\n",
      "   macro avg       0.82      0.53      0.52      1098\n",
      "weighted avg       0.84      0.85      0.79      1098\n",
      "\n",
      "[[920   3]\n",
      " [164  11]]\n"
     ]
    }
   ],
   "source": [
    "#lets check the scoring metrics of logistic regression in more detail\n",
    "logreg = LogisticRegression(penalty = 'l2', C=0.1, solver='liblinear')\n",
    "logreg.fit(X_train,y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7429685807150596"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_prob=logreg.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot roc curve\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr,tpr,thresholds=roc_curve(y_test, y_pred_prob)\n",
    "plt.plot([0,1],[0,1], 'k--')\n",
    "plt.plot(fpr,tpr,label='logreg')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('Logistic regression ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an issue with this prediction. The above model has done pretty well in predicting the true negatives. However, the model does miserably poor jobs in predicting the true postives. This is an issue of imbalanced dataset. Our data is highly imbalanced and in such instance, default decision threshold generally performs poorly. Therefore, in the next step, I will tune the threshold to improve recall of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I am more interested to correctly identify the people with CHD. That is, I want to maximize the recall value. However, the recall value for positive cases (occurrence of CHD) is very low (0.06). Therefore, in the next step, I will identify the threshold at which the F1 score is maximum by giving more weight to recall (beta = 1.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_pred_prob(y_pred_prob, new_threshold):\n",
    "    \"\"\"Adjust predicted probabilities to match new threshold value\"\"\"\n",
    "    \n",
    "    return [1 if y >= new_threshold else 0 for y in y_pred_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4976844705155913\n",
      "optimum threshold 0.17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "# Calculate F1 Score Curve\n",
    "f_beta = []\n",
    "thresholds = np.arange(0, 1, 0.001)\n",
    "for t in thresholds:\n",
    "    adjusted_y_pred = adjust_pred_prob(y_pred_prob, new_threshold=t)\n",
    "    f = fbeta_score(y_test, adjusted_y_pred, beta=1.5)\n",
    "    f_beta.append(f)\n",
    "\n",
    "max_score = max(f_beta)\n",
    "max_index = f_beta.index(max_score)\n",
    "print(max_score)\n",
    "print('optimum threshold', thresholds[max_index])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.64      0.76       923\n",
      "           1       0.28      0.74      0.41       175\n",
      "\n",
      "    accuracy                           0.66      1098\n",
      "   macro avg       0.60      0.69      0.58      1098\n",
      "weighted avg       0.83      0.66      0.70      1098\n",
      "\n",
      "[[590 333]\n",
      " [ 45 130]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = (logreg.predict_proba(X_test)[:,1] >= 0.157).astype('int')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot demonstrating F1 score, precision and recall at different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply threshold to positive probabilities to create labels\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify the optimum threshold and get confusion matrix\n",
    "probs = y_pred_prob.tolist()\n",
    "thresholds = np.arange(0, 1, 0.001)\n",
    "scores = [f1_score(y_test, to_labels(probs, t)) for t in thresholds]\n",
    "max_score = max(scores)\n",
    "max_index =  scores.index(max_score)\n",
    "y_pred = (logreg.predict_proba(X_test)[:,1] >= thresholds[max_index]).astype('int')\n",
    "print('optimum threshold', thresholds[max_index])\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(penalty = 'l2', C=100, solver='liblinear')\n",
    "logreg.fit(X_train,y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)\n",
    "y_pred_prob=logreg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_pred_prob(y_pred_prob, new_threshold):\n",
    "    \"\"\"Adjust predicted probabilities to match new threshold value\"\"\"\n",
    "    \n",
    "    return [1 if y >= new_threshold else 0 for y in y_pred_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_lr = logreg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "# Calculate Precision and Recall Curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
    "thresholds = np.append(thresholds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F1 Score Curve\n",
    "f1_points = []\n",
    "\n",
    "for t in thresholds:\n",
    "        adjusted_y_pred = adjust_pred_prob(y_pred_prob, new_threshold=t)\n",
    "        new_f1 = f1_score(y_test, adjusted_y_pred)\n",
    "        f1_points.append(new_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(thresholds, precision, color='blue')\n",
    "plt.plot(thresholds, recall, color='red')\n",
    "plt.plot(thresholds, f1_points, color='green')\n",
    "plt.title('Precision Recall Curve - GradientBoosting')\n",
    "plt.legend(('Precision', 'Recall', 'F1-Score'))\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Proportion')\n",
    "plt.axvline(x=.158, color='black', linestyle='--')\n",
    "plt.text(.08,.50,'High Risk Threshold',rotation=90)\n",
    "plt.axvline(x=.50, color='black', linestyle='--')\n",
    "plt.text(.475,.50,'Default Threshold',rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Will undersampling perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the training dataset\n",
    "new_df = pd.concat([pd.DataFrame(X_train).reset_index(drop=True), pd.DataFrame(y_train).reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of rows for each class\n",
    "new_df.TenYearCHD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the new df\n",
    "shuffled_df = new_df.sample(frac=1,random_state=4)\n",
    "# Put all the CHD in a separate dataset\n",
    "CHD_df = new_df.loc[new_df['TenYearCHD'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly select 437 observations from the non-fraud (majority class)\n",
    "non_CHD_df = shuffled_df.loc[shuffled_df['TenYearCHD'] == 0].sample(n=382,random_state=42)\n",
    "\n",
    "# Concatenate both dataframes again\n",
    "resampled_df = pd.concat([CHD_df, non_CHD_df])\n",
    "\n",
    "# check new class counts\n",
    "resampled_df.TenYearCHD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = resampled_df.drop(columns=['TenYearCHD'])\n",
    "y = resampled_df.TenYearCHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "models = [\n",
    "          ('KNN', KNeighborsClassifier()),      \n",
    "          ('Logistic Regression', LogisticRegression()), \n",
    "          ('Random Forest', RandomForestClassifier()),\n",
    "          ('Gradient Boost', GradientBoostingClassifier()),\n",
    "          ('SVM', SVC()),\n",
    "          ('Naive Bayes', GaussianNB())\n",
    "        ]\n",
    "names=[]\n",
    "roc_auc_score = []\n",
    "f1_score=[]\n",
    "precision_score=[]\n",
    "recall_score=[]\n",
    "for name, model in models:\n",
    "        roc_auc = cross_val_score(model, X, y, cv=5, scoring='roc_auc')\n",
    "        f1 = cross_val_score(model, X, y, cv=5, scoring='f1')\n",
    "        precision = cross_val_score(model, X, y, cv=5, scoring='precision')\n",
    "        recall = cross_val_score(model, X, y, cv=5, scoring='recall')\n",
    "        clf = model.fit(X, y)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        names.append(name)\n",
    "        roc_auc_score.append(roc_auc.mean())\n",
    "        f1_score.append(f1.mean())\n",
    "        precision_score.append(precision.mean())\n",
    "        recall_score.append(recall.mean())\n",
    "        #print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.DataFrame([names, roc_auc_score, f1_score, precision_score, recall_score]).T\n",
    "score.columns = ['Algorithm', 'Roc_auc_score', 'F1_score', 'Precision', 'Recall']\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the best model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X,y)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression with Undersampling did not perform better than the complete dataset. Therefore, our final model is logistic regression with full dataset using threshold of 0.17."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data quantity assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim, cv, n_jobs=1, train_sizes=np.linspace(.1, 1.0, 10)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "title = \"Learning Curves (Logistic regression)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = LogisticRegression(penalty = 'l1', C=1, solver='liblinear', random_state=1)\n",
    "plot_learning_curve(estimator, title, X_train, y_train, ylim=(0.8, 1),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows that training and cross-validation scores are converging together which suggest that additional data will probably not imporove the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
